![HPEDEVlogo](Pictures/hpe-dev-logo.png)      ![Sparklogo](Pictures/spark.png)

# Welcome to the WoD Developer Hack Shack
[WoD Developer Community Team](https://wod.io)

<p align="center">
  <img src="Pictures/hackshackdisco.png">
  
</p>

# WoD Developer Workshop




# Introduction to Spark101
In this workshop we’ll go through some of basics concepts around Apache Spark.
Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.

# Authors: , [Gerhard Wenzel](mailto:gerhard.wenzel@hpe.com), [Chris Snow](mailto:chris.snow@hpe.com), and [Frederic Passeron](mailto:frederic.passeron@hpe.com) 

## Handouts
You can freely copy the Jupyter Notebooks, including their output, in order to practice back at your office at your own pace, leveraging a local installation of Jupyter Notebook on your laptop.
- You install the Jupyter Notebook application from [here](https://jupyter.org/install). 
- A Beginners Guide is also available [here](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)


## Lab flow
HPE Developer Workshops-on-Demand are delivered through a central point that allows a portable, dynamic version of the lab guides. Rather than using standard PDF files which always end in copy / paste errors from the lab guide into the TS sessions, this year we decided to innovate and introduce a brand-new infrastructure. We will leverage a JupyterHub server on which all the different lab guides will be stored in a notebook format (*.ipynb).

In a nutshell, a notebook works as follows:

• A Notebook is a series de cells

• Notebook uses a kernel (visible in the upper right corner of the Notebook)

• Cell can be Markdown or Code (in the selected kernel)

• To Run a cell use:

    o The Play Button at the top
    o Ctrl-Enter (run and stay on same cell)
    o Shift-Enter (run and move to next cell)
    
• Running a markdown cell is just rendering it

• Running a Code cell runs the code and display the output just below the cell

• When a cell is running it displays a [*] to its left, then when finished, it displays a counter of the number of execution of that cell

• You cannot run a cell when another is already running but you can interrupt a running cell with the stop button

### Pre-requisites

You should have basic Python knowledge and be familiar with using Jupyter Notebooks.  If not, the following free hands-on workshops are recommended:

 - [Python 101](https://hackshack.hpedev.io/workshop/15)
 - [Jupyter Notebooks 101](https://hackshack.hpedev.io/workshop/25)
 
 If you are completely new to machine learning, the following free course is recommended to understand the concepts:
 
 - [Artificial Intelligence & Machine Learning Concepts](https://learn.ezmeral.software.hpe.com/page/artificial-intelligence-machine-learning)



Enjoy the labs ! :-)



## Workflow

### Lab 1: Spark Basics.
Description: In this section, we’ll go through some of tyhe fundamentals of Apache Sparks like RDDs and many other things. 

* [Lab 1](1-WKSHP-Spark_Basics.ipynb)


# Thank you!
![grommet.JPG](Pictures/grommet.JPG)


```python

```



```bash

```
