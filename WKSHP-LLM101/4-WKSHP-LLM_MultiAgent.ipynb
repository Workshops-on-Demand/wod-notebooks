{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Exploring LLM Agents in LL-Mesh\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll explore the concept of **LLM Agents** within the LL-Mesh platform. LL-Mesh provides all the necessary tools to build a powerful agentic system by handling:\n",
    "\n",
    "- **Tool Repository**\n",
    "- **Reasoning Engine**\n",
    "- **Multi-Agents Task Force**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    "- Understand the concept of LLM Agents and how they operate within LL-Mesh.\n",
    "- Learn the differences between the Star and Snowflake architectures for coordinating multi-agent systems.\n",
    "- Define and manage tasks for multiple agents using LL-Mesh's Agent Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of LLM Agents\n",
    "\n",
    "### What is an Agent?\n",
    "\n",
    "In the context of LLM, an **agent** is an autonomous entity capable of:\n",
    "\n",
    "- **Perceiving its environment**: Agents can gather and interpret information from their surroundings.\n",
    "- **Making decisions**: Based on the information perceived, agents can decide on the best course of action.\n",
    "- **Acting on decisions**: Agents execute actions that help achieve specific objectives.\n",
    "\n",
    "These agents can operate independently or interact with one another to optimize their collective performance, depending on the complexity of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Multi-Agent AI?\n",
    "\n",
    "**Multi-Agent AI** involves coordinating multiple agents, each specialized in a specific domain or function, to collaborate and achieve a common goal. These agents can handle:\n",
    "\n",
    "- **Task Division**: Agents can divide a complex task into smaller, manageable parts.\n",
    "- **Specialization**: Each agent may specialize in a particular function, such as information retrieval, summarization, or decision-making.\n",
    "- **Collaboration**: Agents can communicate and share information, enabling more effective and efficient task execution.\n",
    "\n",
    "Managing such agents typically requires advanced coding and deep knowledge of agent-based systems. However, **LL-Mesh simplifies** this process by providing high-level abstraction through intuitive prompts and configuration files. This allows users to focus on defining tasks and desired outcomes, while LL-Mesh handles the coordination, task distribution, and result aggregation behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Options for LLM Agents in LL-Mesh\n",
    "\n",
    "LL-Mesh offers two primary architectural models for managing LLM Agents: the **Star Architecture** and the **Snowflake Architecture**:\n",
    "\n",
    "In the **Star** architecture, a central Reasoning Engine powered by an LLM orchestrates various tools. This setup enables a single chatbot agent to manage and execute tasks using a suite of individual tools, providing centralized control and streamlined management.\n",
    "\n",
    "The **Snowflake** architecture expands on the Star model by introducing multiple LLM-equipped agents. These agents collaborate, sharing resources and tasks, which enhances the system's ability to handle complex operations. This distributed approach significantly improves performance through cooperative task execution.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Pictures/agents.png\" alt=\"Multi Agents Types\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.11.8+ installed on your system.\n",
    "- LL-Mesh library installed. If not, install it using: `pip install 'llmesh[agents]'`\n",
    "- API keys for the LLM services you plan to use (e.g., OpenAI, Azure).\n",
    "\n",
    "Note: These prerequisites have already been met in the lab environment provided. You do not need to install or configure anything manually. For this session, we will be using Llama 3.0 as the LLM model.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Pictures/setup.png\" alt=\"LL-Mesh Chat\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Repository\n",
    "\n",
    "Agents in LL-Mesh rely on **tools** to perform specialized tasks such as information retrieval, document summarization, or data analysis. These tools act as extensions to the agents' capabilities, allowing them to efficiently complete complex operations. The effectiveness of the system is greatly enhanced by how well these tools are organized and accessed, making **tool management** a critical aspect of working with multi-agent systems.\n",
    "\n",
    "The **Tool Repository** service in LL-Mesh is designed to simplify and automate the storage, management, and retrieval of tools. This service leverages the concepts we explored earlier to ensure that agents have seamless access to a wide range of tools, along with their associated metadata, to execute tasks effectively and efficiently.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "1. **Dynamic Tool Storage**:\n",
    "   - Allows for adding tools with associated metadata, including tool name, description, function, and usage parameters.\n",
    "   - Supports a variety of tool types, from pre-built utilities to custom implementations tailored for specific agent tasks.\n",
    "   - Ensures that tools are organized and readily available for use by multiple agents.\n",
    "\n",
    "2. **Tool Retrieval Based on Criteria**:\n",
    "   - Provides flexible search and retrieval functionality, enabling agents to access tools based on specific criteria such as task requirements, tool type, or metadata attributes.\n",
    "   - Ensures that the right tools are selected for the right tasks, optimizing the performance of the multi-agent system.\n",
    "\n",
    "3. **Metadata Management**:\n",
    "   - Stores relevant metadata for each tool, including versioning, author information, last usage, and specific capabilities.\n",
    "   - Metadata can be queried and used to decide which tools are best suited for certain tasks or environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r'Field \"model_name\" in Config has conflict with protected namespace \"model_\".*',\n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athon.agents import ToolRepository\n",
    "\n",
    "# Example configuration for the Tool Repository\n",
    "REPO_CONFIG = {\n",
    "    'type': 'LangChainStructured'\n",
    "}\n",
    "\n",
    "# Initialize the Tool Repository with the provided configuration\n",
    "tool_repository = ToolRepository.create(REPO_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Example tool and metadata to be added to the repository\n",
    "@tool\n",
    "def text_summarizer(text: str) -> str:\n",
    "    \"\"\"A simple text summarizer function\"\"\"\n",
    "    return text[:50] \n",
    "\n",
    "metadata = {\n",
    "    'category': 'NLP',\n",
    "    'version': '1.0',\n",
    "    'author': 'John Doe'\n",
    "}\n",
    "\n",
    "# Add the tool to the repository\n",
    "add_result = tool_repository.add_tool(text_summarizer, metadata)\n",
    "\n",
    "if add_result.status == \"success\":\n",
    "    print(\"Tool added successfully.\")\n",
    "else:\n",
    "    print(f\"ERROR:\\n{add_result.error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve tools with a metadata filter\n",
    "metadata_filter = {'category': 'NLP'}\n",
    "get_result = tool_repository.get_tools(metadata_filter)\n",
    "\n",
    "if get_result.status == \"success\":\n",
    "    print(f\"RETRIEVED TOOLS:\\n{get_result.tools}\")\n",
    "else:\n",
    "    print(f\"ERROR:\\n{get_result.error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning Engine\n",
    "\n",
    "As we explored earlier, agents in LL-Mesh can perform complex tasks by leveraging a suite of tools. However, for agents to deliver truly intelligent, context-aware responses, they must coordinate their tools effectively. This is where the **Reasoning Engine** plays a central role. The Reasoning Engine orchestrates interactions between the **LLM** and various tools, enabling agents to seamlessly combine their decision-making capabilities with tool-based actions.\n",
    "\n",
    "The **Reasoning Engine** in LL-Mesh extends the chat capabilities by managing the dynamic integration of tools with the LLM, allowing for real-time decision-making and execution of tasks. This service ensures that the LLM-generated responses are not only contextually relevant but also actionable by using the appropriate tools from the Tool Repository.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "1. **Tool Orchestration**:\n",
    "   - The Reasoning Engine coordinates between the LLM and the tools, deciding which tools to invoke based on the context and user input.\n",
    "   - Dynamically loads and executes tools based on the task requirements, optimizing the use of each tool within the multi-agent system.\n",
    "\n",
    "2. **Memory Management**:\n",
    "   - The Reasoning Engine handles the storage and retrieval of relevant memory for ongoing tasks or conversations, enabling agents to \"remember\" prior steps and interactions.\n",
    "   - Supports **memory clearing** and reconfiguration, allowing users to reset or adjust the scope of memory to handle different workflows or scenarios.\n",
    "   - Provides the ability to manage the agent's memory across sessions, ensuring that relevant context is preserved across conversations or tasks.\n",
    "\n",
    "3. **Dynamic Configuration**:\n",
    "   - Allows users to configure and adjust the Reasoning Engine's behavior dynamically, tailoring the interaction between LLMs and tools to specific tasks.\n",
    "   - Users can modify which tools are loaded, how the tools interact, and how memory is used during task execution, giving fine-grained control over how agents perform in real-time.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Pictures/engine.png\" alt=\"Multi Agents Types\" width=\"800\">\n",
    "</div>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Force\n",
    "\n",
    "The **Task Force Multi-Agents** service in LL-Mesh enables the orchestration of complex tasks through a network of specialized agents. This service allows users to define a structured workflow, where each agent is assigned a specific task, and these tasks are executed in sequence or in parallel, depending on the defined methodology. The **Task Force** service ensures that each task is handled efficiently by leveraging multiple agents and their respective tools, all while being orchestrated by the reasoning power of an LLM.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "1. **LLM-Driven Planning**:\n",
    "   - The Task Force integrates with an **LLM** to plan the sequence of tasks, ensuring that the workflow is intelligently coordinated.\n",
    "   - The LLM can generate high-level strategies for completing tasks based on user input, and the Task Force orchestrates the execution across agents.\n",
    "\n",
    "2. **Agent Specialization**:\n",
    "   - Each agent in the Task Force can be specialized for a particular task, such as data analysis, report summarization, or presentation creation.\n",
    "   - The behavior of each agent can be tailored through prompts that define their role, backstory, and goals.\n",
    "\n",
    "3. **Task-Oriented Workflow**:\n",
    "   - Allows users to define complex, multi-step tasks and assign each step to a dedicated agent.\n",
    "   - Supports both **sequential** and **parallel** task execution, offering flexibility in how tasks are processed.\n",
    "   - Users can configure task parameters, expected outputs, and agent behaviors through easy-to-define prompts and configuration files.\n",
    "\n",
    "4. **Tool Integration**:\n",
    "   - Agents in the Task Force can utilize a suite of tools, such as data fetchers, summarizers, or presentation builders, to complete their tasks.\n",
    "   - Tools are assigned to agents based on their roles, and these tools are dynamically loaded and executed during task completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = os.path.join('Data', '.env')\n",
    "\n",
    "# Load environment variables from the .env file located in the Data folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "#Â Read environment variables\n",
    "wod_api_key = os.getenv('WOD_LLM101_API_KEY')\n",
    "if not wod_api_key:\n",
    "    raise ValueError(\"API key is not set in environment variables.\")\n",
    "wod_model = os.getenv('WOD_LLM101_MODEL_NAME')\n",
    "if not wod_model:\n",
    "    raise ValueError(\"Model name is not set in environment variables.\")\n",
    "wod_base_url = os.getenv('WOD_LLM101_BASE_URL')\n",
    "if not wod_base_url:\n",
    "    raise ValueError(\"Base URL is not set in environment variables.\")\n",
    "\n",
    "# Set endpoint environment variable\n",
    "os.environ[\"OPENAI_API_BASE\"] = wod_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athon.agents import TaskForce\n",
    "\n",
    "# Configuration for the Task Force Multi-Agents\n",
    "TASK_FORCE_CONFIG = {\n",
    "    'type': 'CrewAIMultiAgent',\n",
    "    'plan_type': 'Sequential',\n",
    "    'tasks': [\n",
    "        {\n",
    "            'description': 'Perform research to gather information for a blog post on {request}.',\n",
    "            'expected_output': 'A summary of key insights, facts, and trends related to the topic.',\n",
    "            'agent': {\n",
    "                'role': 'Research Agent',\n",
    "                'goal': 'Gather relevant information for the blog post',\n",
    "                'backstory': 'Expert in researching and summarizing information quickly and accurately',\n",
    "                'tools': []\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'description': 'Generate a structured outline for a blog post on {request} based on the research.',\n",
    "            'expected_output': 'A detailed blog post outline with 3-5 main sections.',\n",
    "            'agent': {\n",
    "                'role': 'Outline Agent',\n",
    "                'goal': 'Create a comprehensive blog post outline',\n",
    "                'backstory': 'Expert in structuring content into engaging and informative blog outlines',\n",
    "                'tools': []\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'description': 'Develop a complete blog post including an introduction, main content, and conclusion.',\n",
    "            'expected_output': 'A full blog post of around 500-800 words.',\n",
    "            'agent': {\n",
    "                'role': 'Content Development Agent',\n",
    "                'goal': 'Write a well-researched blog post with intro, body, and conclusion',\n",
    "                'backstory': 'Skilled at turning outlines into engaging and coherent blog posts',\n",
    "                'tools': []\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'description': 'Optimize the blog post for SEO by adding keywords, hashtags, and improving readability.',\n",
    "            'expected_output': 'An SEO-optimized version of the blog post, including keywords, meta descriptions, and hashtags.',\n",
    "            'agent': {\n",
    "                'role': 'SEO Agent',\n",
    "                'goal': 'Enhance the blog post with SEO optimizations',\n",
    "                'backstory': 'Expert in applying SEO strategies to improve blog visibility and ranking',\n",
    "                'tools': []\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'description': 'Perform a final check for coherence, clarity, and overall quality of the blog post.',\n",
    "            'expected_output': 'A polished, ready-to-publish blog post.',\n",
    "            'agent': {\n",
    "                'role': 'Final Agent',\n",
    "                'goal': 'Ensure the blog post is ready for publication',\n",
    "                'backstory': 'Final quality control expert ensuring the post is polished and publication-ready',\n",
    "                'tools': []\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'llm': {\n",
    "        'type': 'LangChainChatOpenAI',\n",
    "        'api_key': wod_api_key,\n",
    "        'model_name': \"openai/\" + wod_model,\n",
    "        'base_url': wod_base_url\n",
    "    },\n",
    "    'verbose': True,\n",
    "    'memory': False\n",
    "}\n",
    "\n",
    "# Initialize the Task Force with the provided configuration\n",
    "task_force = TaskForce.create(TASK_FORCE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the task force with an input message\n",
    "input_message = \"Write a blog post about the importance of renewable energy.\"\n",
    "result = task_force.run(input_message)\n",
    "\n",
    "# Handle the response\n",
    "if result.status == \"success\":\n",
    "    print(f\"COMPLETION:\\n{result.completion}\")\n",
    "else:\n",
    "    print(f\"ERROR:\\n{result.error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next [**Lab 5 Retrieval-Augmented Generation (RAG)**](5-WKSHP-LLM_RAG.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
